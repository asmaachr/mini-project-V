{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8d4a3f-bb97-418d-810e-d55970e5afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173ae4ed-e9f8-4d23-8e5c-2f58b86fc466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_clean</th>\n",
       "      <th>q2_clean</th>\n",
       "      <th>q1_tokenized</th>\n",
       "      <th>q2_tokenized</th>\n",
       "      <th>...</th>\n",
       "      <th>q1_count</th>\n",
       "      <th>q2_count</th>\n",
       "      <th>intersection_q1_q2_token</th>\n",
       "      <th>intersection_q1_q2_token_count</th>\n",
       "      <th>q1_stemmed_j</th>\n",
       "      <th>q2_stemmed_j</th>\n",
       "      <th>min_value</th>\n",
       "      <th>max_value</th>\n",
       "      <th>perc_count_min</th>\n",
       "      <th>perc_count_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>['what', 'is', 'the', 'step', 'by', 'step', 'g...</td>\n",
       "      <td>['what', 'is', 'the', 'step', 'by', 'step', 'g...</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>{'what', 'market', 'step', 'to', 'guide', 'sha...</td>\n",
       "      <td>11</td>\n",
       "      <td>step step guid invest share market india</td>\n",
       "      <td>step step guid invest share market</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the story of Kohinoor KohiNoor Diamond</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>['what', 'is', 'the', 'story', 'of', 'kohinoor...</td>\n",
       "      <td>['what', 'would', 'happen', 'if', 'the', 'indi...</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>{'what', 'the', 'diamond', 'kohinoor'}</td>\n",
       "      <td>4</td>\n",
       "      <td>stori kohinoor kohinoor diamond</td>\n",
       "      <td>would happen indian govern stole kohinoor kohi...</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>['how', 'can', 'i', 'increase', 'the', 'speed'...</td>\n",
       "      <td>['how', 'can', 'internet', 'speed', 'be', 'inc...</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>{'how', 'speed', 'internet', 'can'}</td>\n",
       "      <td>4</td>\n",
       "      <td>increas speed internet connect use vpn</td>\n",
       "      <td>internet speed increas hack dn</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Why am I mentally very lonely How can I solve it</td>\n",
       "      <td>Find the remainder when math2324math is divide...</td>\n",
       "      <td>['why', 'am', 'i', 'mentally', 'very', 'lonely...</td>\n",
       "      <td>['find', 'the', 'remainder', 'when', 'math2324...</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>set()</td>\n",
       "      <td>0</td>\n",
       "      <td>mental lone solv</td>\n",
       "      <td>find remaind math2324math divid 2423</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>Which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>Which fish would survive in salt water</td>\n",
       "      <td>['which', 'one', 'dissolve', 'in', 'water', 'q...</td>\n",
       "      <td>['which', 'fish', 'would', 'survive', 'in', 's...</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>{'salt', 'which', 'water', 'in'}</td>\n",
       "      <td>4</td>\n",
       "      <td>one dissolv water quikli sugar salt methan car...</td>\n",
       "      <td>fish would surviv salt water</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1   \n",
       "0   0     1     2  What is the step by step guide to invest in sh...  \\\n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate   \n",
       "0  What is the step by step guide to invest in sh...             0  \\\n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "\n",
       "                                            q1_clean   \n",
       "0  What is the step by step guide to invest in sh...  \\\n",
       "1     What is the story of Kohinoor KohiNoor Diamond   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3   Why am I mentally very lonely How can I solve it   \n",
       "4  Which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                            q2_clean   \n",
       "0  What is the step by step guide to invest in sh...  \\\n",
       "1  What would happen if the Indian government sto...   \n",
       "2  How can Internet speed be increased by hacking...   \n",
       "3  Find the remainder when math2324math is divide...   \n",
       "4             Which fish would survive in salt water   \n",
       "\n",
       "                                        q1_tokenized   \n",
       "0  ['what', 'is', 'the', 'step', 'by', 'step', 'g...  \\\n",
       "1  ['what', 'is', 'the', 'story', 'of', 'kohinoor...   \n",
       "2  ['how', 'can', 'i', 'increase', 'the', 'speed'...   \n",
       "3  ['why', 'am', 'i', 'mentally', 'very', 'lonely...   \n",
       "4  ['which', 'one', 'dissolve', 'in', 'water', 'q...   \n",
       "\n",
       "                                        q2_tokenized  ... q1_count q2_count   \n",
       "0  ['what', 'is', 'the', 'step', 'by', 'step', 'g...  ...       14       12  \\\n",
       "1  ['what', 'would', 'happen', 'if', 'the', 'indi...  ...        8       13   \n",
       "2  ['how', 'can', 'internet', 'speed', 'be', 'inc...  ...       14       10   \n",
       "3  ['find', 'the', 'remainder', 'when', 'math2324...  ...       11        9   \n",
       "4  ['which', 'fish', 'would', 'survive', 'in', 's...  ...       13        7   \n",
       "\n",
       "                            intersection_q1_q2_token   \n",
       "0  {'what', 'market', 'step', 'to', 'guide', 'sha...  \\\n",
       "1             {'what', 'the', 'diamond', 'kohinoor'}   \n",
       "2                {'how', 'speed', 'internet', 'can'}   \n",
       "3                                              set()   \n",
       "4                   {'salt', 'which', 'water', 'in'}   \n",
       "\n",
       "  intersection_q1_q2_token_count   \n",
       "0                             11  \\\n",
       "1                              4   \n",
       "2                              4   \n",
       "3                              0   \n",
       "4                              4   \n",
       "\n",
       "                                        q1_stemmed_j   \n",
       "0           step step guid invest share market india  \\\n",
       "1                    stori kohinoor kohinoor diamond   \n",
       "2             increas speed internet connect use vpn   \n",
       "3                                   mental lone solv   \n",
       "4  one dissolv water quikli sugar salt methan car...   \n",
       "\n",
       "                                        q2_stemmed_j min_value  max_value   \n",
       "0                 step step guid invest share market        12         14  \\\n",
       "1  would happen indian govern stole kohinoor kohi...         8         13   \n",
       "2                     internet speed increas hack dn        10         14   \n",
       "3               find remaind math2324math divid 2423         9         11   \n",
       "4                       fish would surviv salt water         7         13   \n",
       "\n",
       "  perc_count_min perc_count_max  \n",
       "0       0.916667       0.785714  \n",
       "1       0.500000       0.307692  \n",
       "2       0.400000       0.285714  \n",
       "3       0.000000       0.000000  \n",
       "4       0.571429       0.307692  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f22b66d3-eeaa-4167-9ad0-8362c6f5a648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                 0\n",
       "qid1                               0\n",
       "qid2                               0\n",
       "question1                          0\n",
       "question2                          0\n",
       "is_duplicate                       0\n",
       "q1_clean                          12\n",
       "q2_clean                           2\n",
       "q1_tokenized                       0\n",
       "q2_tokenized                       0\n",
       "q1_nostop                          0\n",
       "q2_nostop                          0\n",
       "q1_stemmed                         0\n",
       "q2_stemmed                         0\n",
       "q1_count                           0\n",
       "q2_count                           0\n",
       "intersection_q1_q2_token           0\n",
       "intersection_q1_q2_token_count     0\n",
       "q1_stemmed_j                      78\n",
       "q2_stemmed_j                      64\n",
       "min_value                          0\n",
       "max_value                          0\n",
       "perc_count_min                    14\n",
       "perc_count_max                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9972452-e88e-4ffa-8f32-28ee060a1dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['q1_clean', 'q2_clean'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "266e024d-06b6-4398-9921-40a6c8e43eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404273, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f392671-7718-43ae-808c-a3b1a33dede7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.3.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (6.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a6abe5e-4f0f-4bc9-8570-9327861cb15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df41cf5-c87a-4e71-a89b-fb9d24b7809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the tokenized words from 'q1_tokenized' and 'q2_tokenized'\n",
    "sentences = df['q1_tokenized'].tolist() + df['q2_tokenized'].tolist()\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "419de061-2f20-420f-8b40-07da108cded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the average word embeddings\n",
    "def calculate_average_embedding(tokens):\n",
    "    embeddings = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # Return zero vector if no valid word embeddings found\n",
    "\n",
    "# Apply the function to calculate average word embeddings for 'q1_tokenized'\n",
    "df['word2vec_q1'] = df['q1_tokenized'].apply(calculate_average_embedding)\n",
    "\n",
    "# Apply the function to calculate average word embeddings for 'q2_tokenized'\n",
    "df['word2vec_q2'] = df['q2_tokenized'].apply(calculate_average_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07254652-749d-4452-a0dd-a6257b09afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "batch_size = 1000  # Define the batch size\n",
    "\n",
    "# Calculate the similarity values in batches\n",
    "similarity_values = []\n",
    "num_batches = len(df) // batch_size + 1  # Calculate the number of batches\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, len(df))\n",
    "    batch_q1 = df['word2vec_q1'].tolist()[start_idx:end_idx]\n",
    "    batch_q2 = df['word2vec_q2'].tolist()[start_idx:end_idx]\n",
    "    \n",
    "    batch_similarity = cosine_similarity(batch_q1, batch_q2).diagonal()\n",
    "    similarity_values.extend(batch_similarity)\n",
    "\n",
    "# Add the similarity values as a new column in the DataFrame\n",
    "df['similarity_values'] = similarity_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c2af2-cc60-45d9-8167-4ffe1a42ca68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19751beb-a7a0-4759-80b5-ecf23a01a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b1a6921-8bdc-46d1-9ab9-7cb17d2acca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['perc_count_min','perc_count_max','similarity_values']]\n",
    "y=df['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd4572de-e54d-489d-8040-151cc3b78fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d11e70c-84c5-48aa-8c1a-32d1e0cce5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6519674229634714\n",
      "Testing Accuracy: 0.6483829076742317\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# # Calculate the training accuracy\n",
    "train_accuracy = model.score(X_train, y_train)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# # Calculate the testing accuracy\n",
    "test_accuracy = model.score(X_test, y_test)\n",
    "print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7a245b5-8cdd-4841-8fcc-78d0b69cb52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7086309358168067\n",
      "Testing Accuracy: 0.6987446663780842\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "train_accuracy = model.score(X_train, y_train)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Calculate the testing accuracy\n",
    "test_accuracy = model.score(X_test, y_test)\n",
    "print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b707d26-d8f5-4d76-b8c4-4a992f6f3f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 23:09:18.574247: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-06 23:09:18.794309: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# simple Network\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8007e830-d20d-4fbb-9300-d4ce0ac0f7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66666667, 0.66666667, 0.99844098],\n",
       "       [0.16666667, 0.125     , 0.98933506],\n",
       "       [1.        , 0.7       , 0.9995839 ],\n",
       "       ...,\n",
       "       [0.71428571, 0.71428571, 0.99957973],\n",
       "       [0.        , 0.        , 0.99283606],\n",
       "       [0.8       , 0.8       , 0.99958801]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d76c0916-5021-48da-8e56-9c374bf1944f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66666667, 0.66666667, 0.9982692 ],\n",
       "       [0.16666667, 0.125     , 0.9890976 ],\n",
       "       [1.        , 0.7       , 0.99959415],\n",
       "       ...,\n",
       "       [0.71428571, 0.71428571, 0.99958426],\n",
       "       [0.        , 0.        , 0.99178833],\n",
       "       [0.8       , 0.8       , 0.99950725]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(X_train, (X_train.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3347f939-49fc-4a62-86d4-2c616a14e3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32342/32342 [==============================] - 82s 3ms/step - loss: 0.5874 - accuracy: 0.6498 - val_loss: 0.5880 - val_accuracy: 0.6526\n",
      "Epoch 2/10\n",
      "32342/32342 [==============================] - 81s 2ms/step - loss: 0.5869 - accuracy: 0.6494 - val_loss: 0.5865 - val_accuracy: 0.6446\n",
      "Epoch 3/10\n",
      "32342/32342 [==============================] - 84s 3ms/step - loss: 0.5869 - accuracy: 0.6494 - val_loss: 0.5874 - val_accuracy: 0.6439\n",
      "Epoch 4/10\n",
      "32342/32342 [==============================] - 86s 3ms/step - loss: 0.5867 - accuracy: 0.6493 - val_loss: 0.5861 - val_accuracy: 0.6442\n",
      "Epoch 5/10\n",
      "32342/32342 [==============================] - 83s 3ms/step - loss: 0.5866 - accuracy: 0.6497 - val_loss: 0.5861 - val_accuracy: 0.6494\n",
      "Epoch 6/10\n",
      "32342/32342 [==============================] - 82s 3ms/step - loss: 0.5867 - accuracy: 0.6501 - val_loss: 0.5861 - val_accuracy: 0.6474\n",
      "Epoch 7/10\n",
      "32342/32342 [==============================] - 83s 3ms/step - loss: 0.5868 - accuracy: 0.6496 - val_loss: 0.5887 - val_accuracy: 0.6515\n",
      "Epoch 8/10\n",
      "32342/32342 [==============================] - 83s 3ms/step - loss: 0.5867 - accuracy: 0.6495 - val_loss: 0.5864 - val_accuracy: 0.6493\n",
      "Epoch 9/10\n",
      "32342/32342 [==============================] - 84s 3ms/step - loss: 0.5868 - accuracy: 0.6498 - val_loss: 0.5893 - val_accuracy: 0.6530\n",
      "Epoch 10/10\n",
      "32342/32342 [==============================] - 83s 3ms/step - loss: 0.5867 - accuracy: 0.6492 - val_loss: 0.5875 - val_accuracy: 0.6407\n",
      "Training Loss: [0.5874279141426086, 0.5868640542030334, 0.5869233012199402, 0.5867403745651245, 0.5866135954856873, 0.5867407917976379, 0.5867621302604675, 0.5867429375648499, 0.5868412256240845, 0.5867210030555725]\n",
      "Training Accuracy: [0.6497814059257507, 0.6493979692459106, 0.649357795715332, 0.649286687374115, 0.6497102975845337, 0.6500720381736755, 0.6495958566665649, 0.6495000123977661, 0.6498215794563293, 0.6492495536804199]\n",
      "Validation Loss: [0.5880185961723328, 0.5864976644515991, 0.5874329209327698, 0.5861291289329529, 0.5861383080482483, 0.5860853791236877, 0.5886912941932678, 0.5864282250404358, 0.5893128514289856, 0.5874943733215332]\n",
      "Validation Accuracy: [0.6525508761405945, 0.6445859670639038, 0.6438810229301453, 0.6442273259162903, 0.6494341492652893, 0.6473934650421143, 0.6514624953269958, 0.6493104696273804, 0.6529961228370667, 0.6406530141830444]\n"
     ]
    }
   ],
   "source": [
    "# Convert the training data into numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Reshape the input arrays to have the correct shape\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 3))\n",
    "\n",
    "# Define the Neural Networks model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(3,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Access the training and validation results\n",
    "train_loss = history.history['loss']            # Training loss values\n",
    "train_accuracy = history.history['accuracy']    # Training accuracy values\n",
    "val_loss = history.history['val_loss']          # Validation loss values\n",
    "val_accuracy = history.history['val_accuracy']  # Validation accuracy values\n",
    "\n",
    "# Print the results\n",
    "print(\"Training Loss:\", train_loss)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Validation Loss:\", val_loss)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75fbcdc-3c27-45b8-a73d-252043acb5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b4d5a8-e63d-4062-aec3-cc299f38a86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d312dd0-7738-4792-a4ff-5e7ab928ba83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6320332-ad8c-439a-9a77-bcdd1024cae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
